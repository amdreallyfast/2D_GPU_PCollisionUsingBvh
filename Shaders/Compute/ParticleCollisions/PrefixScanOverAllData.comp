// REQUIRES Version.comp
// REQUIRES ComputeShaderWorkGroupSizes.comp
// REQUIRES CrossShaderUniformLocations.comp
// REQUIRES SsboBufferBindings.comp
// REQUIRES PrefixScanBuffer.comp

// Y and Z work group sizes default to 1
layout (local_size_x = WORK_GROUP_SIZE_X) in;

// create a shared memory buffer for fast memory operations (better than global), two items per 
// thread
// Note: By definition of keyword "shared", this is shared amongst all threads in a work group.
// Also Note: Every item gets written before it is read, so don't bother initializing with 0.
shared uint[PREFIX_SCAN_ITEMS_PER_WORK_GROUP] fastTempArr;


/*------------------------------------------------------------------------------------------------
Description:
    This is where the magic happens.  Each thread in a work group copies two items from global 
    memory to work-group-shared memory, waits for all the other threads to catch up to the 
    write, performs the scan (up the tree and back down), then writes their two results back to 
    global memory.

    This half of the parallel prefix scan algorithm runs over all the data.  The algorithm needs 
    to run both up and down the tree, and this causes a race condition when other work groups' 
    data has not been operated on.  Solution: This part of the prefix scan only works on a 
    single work group's worth of data in the PrefixSumBuffer, specifically 
    PrefixSumsPerWorkGroup.  The rest of the prefix sums will calculated in the second half in
    PrefixScanOverWorkGroupSums.comp

    Note: This is a parallel prefix sums algorithm that uses shared memory, a binary tree, and 
    no atomic counters to build up a prefix sum within a work group.  The shared memory is 
    advantageous fast shared memory is favorable over having many threads get in line to use 
    atomic counters, of which there are a limited number, on global memory.

    Thanks to developer.nvidia.com, GPU Gems 3, Chapter 39. Parallel Prefix Sum (Scan) with CUDA
    for the algorithm (despite the code golfing variable names and lack of comments, at least 
    they had pictures that I could eventually work out).
    http://http.developer.nvidia.com/GPUGems3/gpugems3_ch39.html

Parameters: None
Returns:    None
Creator:    John Cox, 3/11/2017
------------------------------------------------------------------------------------------------*/
void main()
{
    // doubled because each thread deals with 2 items, so the shared data size is double the 
    // work group size, and everything dealing with indices also doubles them, so just make a 
    // doubled variable up front
    uint doubleGroupThreadIndex = gl_LocalInvocationID.x * 2;
    uint doubleGlobalThreadIndex = gl_GlobalInvocationID.x * 2;

    // Copy from global to shared data for a faster algorithm (and easier index calculations)
    // Note: Two elements per thread.
    fastTempArr[doubleGroupThreadIndex] = PrefixSumsPerWorkGroup[doubleGlobalThreadIndex];
    fastTempArr[doubleGroupThreadIndex + 1] = PrefixSumsPerWorkGroup[doubleGlobalThreadIndex + 1];

    // called simply "offset" in the GPU Gems article, this is a multiplier that works in 
    // conjunction with the thread number to calculate which index pairs are being considered on 
    // each loop by each thread
    uint indexMultiplierDueToDepth = 1;

    // going up divides pair count in half with each level
    for (uint dataPairs = PREFIX_SCAN_ITEMS_PER_WORK_GROUP >> 1; dataPairs > 0; dataPairs >>= 1)
    {
        // wait for other threads in the group to catch up
        barrier();

        // one pair per thread
        // Note: Going up the tree will require fewer pair operations at each level.  Local 
        // thread ID 0 will always be doing something, but higher thread numbers will start 
        // sitting out until the "going down the tree" loop
        if (gl_LocalInvocationID.x < dataPairs)
        {
            uint lesserIndex = (indexMultiplierDueToDepth * (doubleGroupThreadIndex + 1)) - 1;
            uint greaterIndex = (indexMultiplierDueToDepth * (doubleGroupThreadIndex + 2)) - 1;

            fastTempArr[greaterIndex] += fastTempArr[lesserIndex];
        }

        // this is used in the "going down" loop, so do this even if the thread didn't do 
        // anything on this iteration
        indexMultiplierDueToDepth *= 2;
    }

    // only thread 0 should do this (prevents unnecessary writes)
    // Note: No barrier() is necessary here because this algorithm guarantees that thread 0 will 
    // be the last thread to check this condition, at which point it has already written to the 
    // last index in fastTempArr.
    if (doubleGroupThreadIndex == 0)
    {
        // write the work group sum to the group sums buffer
        // Note: After the "going up" loop finishes, the last item in the shared memory array 
        // has the sum of all items in the entire array.  The following "going down" loop will 
        // change the data into a prefix-only sums array, so record the entire sum while it is 
        // still available.
        PrefixSumsOfWorkGroupSums[gl_WorkGroupID.x] = fastTempArr[PREFIX_SCAN_ITEMS_PER_WORK_GROUP - 1];
       
        // this is just part of the algorithm; I don't have an intuitive explanation
        fastTempArr[PREFIX_SCAN_ITEMS_PER_WORK_GROUP - 1] = 0;
    }

    // undo the last loop's indexMultiplierDueToDepth
    // Note: After the last loop, indexMultiplierDueToDepth had been multiplied by 2 as many 
    // times as dataPairs had been divided by 2, so it is now equivalent to PREFIX_SCAN_ITEMS_PER_WORK_GROUP 
    // (assuming that it is a power of 2).  Divide by 2 so that it can be used to calculate the 
    // indices of the first data pair off the root.
    indexMultiplierDueToDepth >>= 1;

    // going down multiplies pair count by 2 with each level
    for (uint dataPairs = 1; dataPairs < PREFIX_SCAN_ITEMS_PER_WORK_GROUP; dataPairs *= 2)
    {
        // wait for the other threads in the group to catch up
        barrier();

        // once again, group thread 0 is always working, but the others may need to sit out for 
        // a few loops
        if (gl_LocalInvocationID.x < dataPairs)
        {
            uint lesserIndex = (indexMultiplierDueToDepth * (doubleGroupThreadIndex + 1)) - 1;
            uint greaterIndex = (indexMultiplierDueToDepth * (doubleGroupThreadIndex + 2)) - 1;

            // this is a swap and a sum, so need a temporary value
            uint temp = fastTempArr[lesserIndex];
            fastTempArr[lesserIndex] = fastTempArr[greaterIndex];
            fastTempArr[greaterIndex] += temp;
        }

        // next level down will have twice the number of data pairs, so each index calculation 
        // needs half the offset due to depth
        indexMultiplierDueToDepth >>= 1;
    }

    // write the data back, two elements per thread, but wait for all the group threads to 
    // finish their loops first
    barrier();
    PrefixSumsPerWorkGroup[doubleGlobalThreadIndex] = fastTempArr[doubleGroupThreadIndex];
    PrefixSumsPerWorkGroup[doubleGlobalThreadIndex + 1] = fastTempArr[doubleGroupThreadIndex + 1];
}

