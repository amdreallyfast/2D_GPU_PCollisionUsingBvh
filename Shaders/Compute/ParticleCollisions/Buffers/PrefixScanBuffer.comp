// REQUIRES SsboBufferBindings.comp
// REQUIRES CrossShaderUniformLocations


// Note: The ParallelSort compute controller should be carefully controlling the number of work 
// groups and therefore the number of threads, so this value shouldn't actually be neccesary for 
// excess thread checks (if gl_GlobalInvocationID.x > uPrefixSumsPerWorkGroupArraySize) { return; }),
// but it is good practice to have a uniform buffer size wherever there is buffer.
layout(location = UNIFORM_LOCATION_ALL_PREFIX_SUMS_SIZE) uniform uint uPrefixSumsPerWorkGroupArraySize;

/*------------------------------------------------------------------------------------------------
Description:
    This is the data that is being scanned AND that is being altered into a prefix sum.
    See explanation of sizes in PrefixSumSsbo.

    The prefix scan has to be split into two parts.  This would not be necessary if GLSL compute 
    shaders had a "hang all threads in the dispatch until they reach this point", but since it 
    only has a "hang all threads in work group until they reach this point", then the parallel 
    prefix scan has to be divided into two parts in order to operate on on a data set larger 
    than GL_MAX_COMPUTE_WORK_GROUP_SIZE * 2 (remember that this scan operates on two integers 
    per thread).  The Khronos documentation says that this variable should be called 
    GL_MAX_COMPUTE_WORK_GROUP_INVOCATIONS, and it may be on another OpenGL implementation than 
    GLLoad.  On my GTX 560M that I am currently programming on, this max value is 1536.  If I 
    want to sort, for example, 10,000 particles, I can't do a prefix sum over a single work 
    group.  So I need to split the jobs up into multiple work groups, then add their sums 
    together with the second half of the prefix scan.  With each work group handling 
    PREFIX_SCAN_ITEMS_PER_WORK_GROUP (1024) sums, and having a separate array of size 
    PREFIX_SCAN_ITEMS_PER_WORK_GROUP for the work group sums, then I can perform a prefix sum 
    over 1024 * 1024 ~= 1M particles.  That's more than enough for my GPU.

    Note: The totalNumberOfOnes value between the buffers is set during in the middle of the 
    prefix scan algorithm of the PrefixSumsOfWorkGroupSums array in the same manner that entries 
    in PrefixSumsOfWorkGroupSums are set in the middle of each work group's prefix scan of 
    PrefixSumsPerWorkGroup.  It is used along with uPrefixSumsPerWorkGroupArraySize in 
    SortIntermediateData.comp to determine the total number of 0s and thus the 1s' offset.

    Prefix sum of 0s = index into PrefixSumsPerWorkGroup - value at that index (sum of 1s)

    Why is there a "number of 1s" variable being used to determine the number of 0s?  Because 
    (1) The 1s go after the 0s, so the index for the 1s requires knowing how many 0s came before.
    (2) You can sum all the 0s in the world and you will still get 0.  Sure, it is possible 
    to count the number of 0s, but then you'll have to use a counting algorithm, not a sum 
    algorithm.

    Also Note: Yes, PrefixSumsOfWorkGroupSums[] are prefix sums of other work group sums, but it 
    is necessary so that values from different work groups can get the full picture of all the 
    prefix sums that came before it.  This is part of Radix Sort.

Creator:    John Cox, 3/11/2017
------------------------------------------------------------------------------------------------*/
layout (std430, binding = PREFIX_SCAN_BUFFER_BINDING) buffer PrefixScanBuffer
{
    uint PrefixSumsOfWorkGroupSums[PREFIX_SCAN_ITEMS_PER_WORK_GROUP];
    uint totalNumberOfOnes;
    uint PrefixSumsPerWorkGroup[];
};

